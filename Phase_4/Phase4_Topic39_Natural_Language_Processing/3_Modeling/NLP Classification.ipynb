{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Natural Language Processing: Classification\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC July 2022\n",
    "<p>Phase 4: Topic 39</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.pardir)\n",
    "#print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importing text preprocessing libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# integrating our preprocessing into a pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Build a very simple stateless transformer:\n",
    "- Cleans/preprocesses text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #define attributes to store if text preprocessing requires fitting from data\n",
    "        pass\n",
    "    \n",
    "    def fit(self, data, y = 0):\n",
    "        # this is where you would fit things like corpus specific stopwords\n",
    "        # fit probable bigrams with bigram model in here\n",
    "        \n",
    "        # save as parameters of Text preprocessor\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, data, y = 0):\n",
    "        fully_normalized_corpus = data.apply(self.process_doc)\n",
    "        \n",
    "        return fully_normalized_corpus\n",
    "        \n",
    "    \n",
    "    def process_doc(self, doc):\n",
    "\n",
    "        #initialize lemmatizer\n",
    "        wnl = WordNetLemmatizer()\n",
    "        stop_words = stopwords.words('english')\n",
    "        \n",
    "        # helper function to change nltk's part of speech tagging to a wordnet format.\n",
    "        def pos_tagger(nltk_tag):\n",
    "            if nltk_tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif nltk_tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif nltk_tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif nltk_tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:         \n",
    "                return None\n",
    "\n",
    "\n",
    "        # remove stop words and punctuations, then lower case\n",
    "        doc_norm = [tok.lower() for tok in word_tokenize(doc) if ((tok.isalpha()) & (tok not in stop_words)) ]\n",
    "\n",
    "        #  POS detection on the result will be important in telling Wordnet's lemmatizer how to lemmatize\n",
    "\n",
    "        # creates list of tuples with tokens and POS tags in wordnet format\n",
    "        wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(doc_norm))) \n",
    "        doc_norm = [wnl.lemmatize(token, pos) for token, pos in wordnet_tagged if pos is not None]\n",
    "\n",
    "        return \" \".join(doc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/satire_nosatire.csv')\n",
    "X = data['body']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      note resignation james mattis secretary defens...\n",
       "1      desperate unwind month nonstop work investigat...\n",
       "2      nearly halfway presidential term donald trump ...\n",
       "3      attempt make amends gross abuse power time int...\n",
       "4      decry senate resolution blame crown prince bru...\n",
       "                             ...                        \n",
       "995    britain opposition leader jeremy corbyn push a...\n",
       "996    turkey take fight islamic state militant syria...\n",
       "997    malaysia seek reparation goldman sachs group i...\n",
       "998    israeli court sentence palestinian year impris...\n",
       "999    least people die due landslide flood trigger t...\n",
       "Name: body, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc = TextPreprocessor()\n",
    "proc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prc_steps = [('token_norm', TextPreprocessor()), ('countvec', CountVectorizer(min_df = 0.05, max_df = 0.95))]\n",
    "preprocess_pipeline = Pipeline(prc_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_tr_proc = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<700x614 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45270 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accuse</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>woman</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  accept  access  accord  account  accuse  act  action  actually  \\\n",
       "0       0       0       0       0        0       0    0       0         0   \n",
       "1       1       0       0       0        0       0    1       1         0   \n",
       "2       0       0       0       0        0       0    0       0         0   \n",
       "3       0       0       0       0        0       0    0       0         0   \n",
       "4       0       0       0       0        0       2    0       0         0   \n",
       "..    ...     ...     ...     ...      ...     ...  ...     ...       ...   \n",
       "695     0       0       0       0        0       0    0       0         0   \n",
       "696     0       0       0       0        1       0    1       0         0   \n",
       "697     0       0       0       0        0       0    2       0         0   \n",
       "698     0       0       0       0        0       0    0       0         0   \n",
       "699     1       0       0       0        0       0    0       0         0   \n",
       "\n",
       "     add  ...  woman  word  work  worker  world  write  year  yes  yet  young  \n",
       "0      0  ...      0     0     0       0      0      0     2    0    0      0  \n",
       "1      0  ...      0     0     0       2      0      2     2    0    0      0  \n",
       "2      0  ...      0     0     0       0      0      0     0    0    0      0  \n",
       "3      0  ...      1     0     0       0      0      0     0    0    0      0  \n",
       "4      0  ...      0     0     1       0      0      1     1    0    0      0  \n",
       "..   ...  ...    ...   ...   ...     ...    ...    ...   ...  ...  ...    ...  \n",
       "695    1  ...      0     0     0       0      0      0     1    0    0      0  \n",
       "696    2  ...      0     0     1       0      1      3     1    0    0      0  \n",
       "697    0  ...      0     0     0       0      0      0     0    0    0      0  \n",
       "698    0  ...      0     0     0       0      0      0     0    0    0      0  \n",
       "699    1  ...      0     0     3       1      0      1     1    0    0      0  \n",
       "\n",
       "[700 rows x 614 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = preprocess_pipeline['countvec'].get_feature_names()\n",
    "\n",
    "pd.DataFrame(X_tr_proc.toarray(), columns = feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Building a document classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Naive Bayes with Multinomial Distribution Likelihood**\n",
    "\n",
    "- Can be effective for modeling document-term frequency matrix to target class relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bayes theorem:\n",
    "\n",
    "$$ P(c|\\textbf{x}) = \\frac{P(\\textbf{x}|c)P(c)}{P(\\textbf{x})} $$\n",
    "\n",
    "- Likelihood; $P(\\textbf{x}|c)$\n",
    "- Prior: $P(c)$\n",
    "- Posterior: $P(c|\\textbf{x}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bayes classifier:\n",
    "    \n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} P(\\textbf{x}|c)P(c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Prior\n",
    "- simply the target fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.504286\n",
       "0    0.495714\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_priors = y_train.value_counts(normalize=True)#/y_train.shape[0]\n",
    "class_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**First step: word count distribution**:\n",
    "\n",
    "- Multinomial distribution (generalization of \n",
    "binomial distribution)\n",
    "\n",
    "For document with $m$ tokens:\n",
    "- dictionary of corpus has $d$ unique tokens.\n",
    "- $\\textbf{x} = (x_1,...., x_d)$ vector of token counts for document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An analogy: $d = 6$ M&M colors\n",
    "\n",
    "Picking $ m $ M&Ms.\n",
    "\n",
    "<img src = \"Images/picking_candy.jpg\" >\n",
    "    \n",
    "Follow multinomial distribution.\n",
    "\n",
    "\n",
    "<a href = \"https://www.mashed.com/679227/the-rarest-mm-color-may-surprise-you/#:~:text=Brown%20is%20currently%20the%20rarest%20color%20of%20M%26M's&text=As%20such%2C%20they%20used%20their,their%20findings%20were%20quite%20surprising.\"> Some interesting facts about M&Ms. </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ P(\\textbf{x}|\\theta) = \\frac{m!}{x_1!x_2!...x_d!} \\theta_{1}^{x_1}\\theta_{2}^{x_2}...\\theta_{d}^{x_d} $$\n",
    "Parameters of distribution:\n",
    "- $\\theta_i$: probability of picking $i^{th}$ token  in dictionary from bag of words\n",
    "\n",
    "**To be estimated from the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Words draws/order are **independent** of each other: the **naive** assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/scrabble.webp\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Second Step: class conditional word count\n",
    "\n",
    "$$ P(\\textbf{x}|c) = \\frac{m!}{x_1!x_2!...x_d!} [\\theta_c]_{1}^{x_1}[\\theta_c]_{2}^{x_2}...[\\theta_c]_{d}^{x_d} $$\n",
    "- $[\\theta_c]$ is **class-dependent** set of probability parameters.\n",
    "\n",
    "Need to fit probability parameters from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Fitting probability parameters for each class**\n",
    "\n",
    "- Very straightforward.\n",
    "- Probability of drawing token $i$ if document class $c$\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci}}{N_c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Count token $i$ occurence across all documents of class $c$\n",
    "- Divide by total token count for all documents of class $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Getting the fit parameters with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accuse</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>woman</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  accept  access  accord  account  accuse  act  action  actually  \\\n",
       "0       0       0       0       0        0       0    0       0         0   \n",
       "1       1       0       0       0        0       0    1       1         0   \n",
       "2       0       0       0       0        0       0    0       0         0   \n",
       "3       0       0       0       0        0       0    0       0         0   \n",
       "4       0       0       0       0        0       2    0       0         0   \n",
       "..    ...     ...     ...     ...      ...     ...  ...     ...       ...   \n",
       "695     0       0       0       0        0       0    0       0         0   \n",
       "696     0       0       0       0        1       0    1       0         0   \n",
       "697     0       0       0       0        0       0    2       0         0   \n",
       "698     0       0       0       0        0       0    0       0         0   \n",
       "699     1       0       0       0        0       0    0       0         0   \n",
       "\n",
       "     add  ...  woman  word  work  worker  world  write  year  yes  yet  young  \n",
       "0      0  ...      0     0     0       0      0      0     2    0    0      0  \n",
       "1      0  ...      0     0     0       2      0      2     2    0    0      0  \n",
       "2      0  ...      0     0     0       0      0      0     0    0    0      0  \n",
       "3      0  ...      1     0     0       0      0      0     0    0    0      0  \n",
       "4      0  ...      0     0     1       0      0      1     1    0    0      0  \n",
       "..   ...  ...    ...   ...   ...     ...    ...    ...   ...  ...  ...    ...  \n",
       "695    1  ...      0     0     0       0      0      0     1    0    0      0  \n",
       "696    2  ...      0     0     1       0      1      3     1    0    0      0  \n",
       "697    0  ...      0     0     0       0      0      0     0    0    0      0  \n",
       "698    0  ...      0     0     0       0      0      0     0    0    0      0  \n",
       "699    1  ...      0     0     3       1      0      1     1    0    0      0  \n",
       "\n",
       "[700 rows x 614 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_mat = pd.DataFrame(X_tr_proc.toarray(), columns = feat_names)\n",
    "bow_mat['target'] = y_train\n",
    "bow_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "say           0.034145\n",
       "year          0.009707\n",
       "trump         0.009338\n",
       "people        0.009281\n",
       "state         0.008373\n",
       "take          0.007578\n",
       "make          0.007067\n",
       "government    0.006812\n",
       "president     0.006784\n",
       "see           0.006698\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_bow_mat = bow_mat[bow_mat['target'] == 1].drop(columns = ['target'])\n",
    "\n",
    "# class 1 token probabilities:\n",
    "N_tok_1 = class1_bow_mat.sum(axis = 0) # token occurence\n",
    "N_1 =  class1_bow_mat.values.sum() # number of tokens\n",
    "\n",
    "# get probabilities for each token: class 1\n",
    "proba_c1 = N_tok_1/N_1\n",
    "\n",
    "proba_c1.sort_values(ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "say           0.031878\n",
       "people        0.008761\n",
       "government    0.008098\n",
       "year          0.007730\n",
       "state         0.007509\n",
       "time          0.007436\n",
       "trump         0.007289\n",
       "president     0.006626\n",
       "make          0.006479\n",
       "take          0.006258\n",
       "dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0_bow_mat = bow_mat[bow_mat['target'] == 0].drop(columns = ['target'])\n",
    "\n",
    "# class 1 token probabilities:\n",
    "N_tok_0 = class0_bow_mat.sum(axis = 0)\n",
    "N_0 =  class0_bow_mat.values.sum() \n",
    "\n",
    "# get probabilities for each token: class 0\n",
    "proba_c0 = N_tok_0/N_0\n",
    "\n",
    "proba_c0.sort_values(ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Computing likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A group of U.S. activists opposed to President Donald Trump’s immigration policies helped migrants in Mexico during a clash with U.S. agents at the border on New Year’s Eve, and dispute their government’s account of the events. Late on Monday, about 150 migrants gathered at the border in Tijuana to try to enter the United States, according to the U.S. activists and a Reuters witness. After learning of a possible conflict, 11 U.S. volunteers who were in Tijuana headed to the border to provide medical assistance and document the events, said Lilith Sinclair, a spokeswoman for the group. The activists, some of whom are part of a group known as the Border Support Network, have said they were banding together to counter what they view as the U.S. government’s violation of asylum seekers’ rights. They have also challenged the U.S. government’s position that agents deployed tear gas after coming under attack. “This attack on migrants peacefully seeking asylum was crippling, inhumane and unprovoked,” Sinclair said in a statement on Wednesday. The clash in Tijuana was the second incident in less than two months in which dozens of migrants tried to cross the border and were met with gas. The activists were not present for the entire confrontation, but did not witness any provocation by migrants in the time they were there, Sinclair, a 24-year-old from Portland, Oregon, said in an interview. When Sinclair arrived, she saw a small group near the border fence, trying to tell agents they planned to seek asylum. She then saw agents deploy tear gas. The U.S. Customs and Border Protection (CBP) agency said it could not immediately respond to a request for comment, citing a backlog due to the U.S. government shutdown. The CBP previously said agents launched smoke, pepper spray and tear gas known as CS gas only after migrants threw rocks. “This is among the lowest levels of response we can give,” said Joshua Wilson, vice president of the San Diego Border Patrol Union. “A rock is deadly force.” A Reuters witness did not see migrants throwing rocks. The Associated Press reported that rocks were flung after tear gas was deployed. The CBP said on Wednesday that an internal investigation of the use of CS gas on Dec. 31 was underway. On Thursday, the Mexican government requested a full investigation. ANTI-FASCISTS Formed in November in response to the migrant caravans that drew Trump’s ire, the activist coalition includes self-described anti-fascists and advocates for causes such as indigenous rights and water access, Sinclair said. Some members met through protests over the Dakota Access Pipeline and a police shooting in Ferguson, Missouri. Mario Osuna, Tijuana’s secretary of municipal development, and a spokesman for the foreign ministry said they had no information about the group. Mexico’s immigration institute did not immediately respond to requests for comment. Under Mexican law, U.S. citizens may undertake voluntary work for up to 180 days without a visa. In mid-November, the group opened a safe house in Tijuana, housing about 25 volunteers at a time, most from the United States, said Evan Duke of Seattle, one of the organizers. The Border Support Network is funded largely by individual donations, Sinclair said. The group mobilized quickly after receiving word of the clash, heading out with warm clothes, medical supplies and water, said Duke, 45. He stayed behind to support volunteers from the safe house, adding that the activists had not transported migrants to the border or otherwise instigated the incident. An independent volunteer, Nathaniel Dennison, a 34-year-old documentary filmmaker based in Virginia, said the mood at the border was “hopeful and peaceful until border patrol acted on asylum seekers, unprovoked.” Dennison said he was struck by three “plastic pellets.” The CBP says it does not deploy rubber bullets but does use pepper balls, a round rubber projectile containing pepper spray. Erick Hernandez, a 24-year-old Salvadoran who tried to enter the United States, said American volunteers helped bridge the language gap at the border. “They spoke with the American side,” he said. “We asked them for a little bit of respect for the children.”'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "able       0\n",
       "accept     0\n",
       "access     2\n",
       "accord     1\n",
       "account    1\n",
       "          ..\n",
       "write      0\n",
       "year       1\n",
       "yes        0\n",
       "yet        0\n",
       "young      0\n",
       "Name: 50, Length: 613, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bow vector for document\n",
    "bow_mat_feat = bow_mat.drop(columns = ['target'])\n",
    "word_vec = bow_mat_feat.iloc[50]\n",
    "word_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is satire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_length = word_vec.sum()\n",
    "article_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class1_likelihood = multinomial.pmf(x = word_vec.values, n = article_length, p =  proba_c1.values)\n",
    "class0_likelihood = multinomial.pmf(x = word_vec.values, n = article_length, p =  proba_c0.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now use Bayes theorem for classifier:\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\min} P(\\textbf{x}|c)P(c)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "with multinomial likelihood\n",
    "\n",
    "$$ P(\\textbf{x}|c) = \\frac{m!}{x_1!x_2!...x_d!} [\\hat{\\theta}_c]_{1}^{x_1}[\\hat{\\theta}_c]_{2}^{x_2}...[\\hat{\\theta}_c]_{d}^{x_d} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and fitted parameters\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci}}{N_c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluate class for this document:\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\min} P(\\textbf{x}|c)P(c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1874946774489244e-190"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_likelihood*class_priors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0066150584687169e-193"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0_likelihood*class_priors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given scale of probabilities:\n",
    "- Comparison done on log scale\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} \\Big[ \\log\\Big(P(\\textbf{x}|c)P(c)\\Big) \\Big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-189.92536832827972"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(class1_likelihood*class_priors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-192.99713657705735"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(class0_likelihood*class_priors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Laplace Smoothing: practical correction\n",
    "\n",
    "- A fudge count $\\alpha$ added to token count in each class.\n",
    "- Avoids issues with having zero counts.\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci} + \\alpha}{N_c + \\alpha d}$$\n",
    "\n",
    "- Typically $\\alpha = 1$. Can tune this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Append Multinomial Naive Bayes Classifier to pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('token_norm', TextPreprocessor()),\n",
       " ('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('multinb', MultinomialNB())]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "mod_pipe = deepcopy(preprocess_pipeline)\n",
    "mod_pipe.steps.append(('multinb', MultinomialNB()))\n",
    "mod_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('token_norm', TextPreprocessor()),\n",
       "                ('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       "                ('multinb', MultinomialNB())])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = mod_pipe.predict(X_test) # automatically applies transforms and predicts on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       153\n",
      "           1       0.96      0.95      0.96       147\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565826330532213"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x2aaa12cf280>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(mod_pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2aaa12bbfd0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(mod_pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- with proper text preprocessing steps\n",
    "- Naive Bayes can perform really well on simple binary classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "TFIDF does not necessarily perform better than CV:\n",
    "- It is just a tool in our toolbelt often worth trying out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('token_norm', TextPreprocessor()),\n",
       " ('tfidf', TfidfVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('multinb', MultinomialNB())]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "tfidfmod_pipe = deepcopy(mod_pipe)\n",
    "tfidfmod_pipe.steps[1] = ('tfidf', TfidfVectorizer(min_df=0.05, max_df=0.95)) # cuts words too rare/too frequent\n",
    "tfidfmod_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tfidfmod_pipe.fit(X_train, y_train)\n",
    "ypred_tfidf = tfidfmod_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9701880752300921"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, ypred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "cell_style": "split",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2aa9f20d2b0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(tfidfmod_pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### With class imbalance\n",
    "\n",
    "- Modification to Multinomial Naive Bayes: Complement Naive Bayes\n",
    "- deals with data skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pretty much same fitting/hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('token_norm', TextPreprocessor()),\n",
       " ('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('compnb', ComplementNB())]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "mod_comp_pipe = deepcopy(preprocess_pipeline)\n",
    "mod_comp_pipe.steps.append(('compnb', ComplementNB()))\n",
    "mod_comp_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mod_comp_pipe.fit(X_train, y_train)\n",
    "y_pred_comp = mod_comp_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       155\n",
      "           1       0.95      0.97      0.96       145\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_comp, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Comparable performance on this balanced dataset. Will perform *much* better on imbalanced dataset than MultinomialNB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
